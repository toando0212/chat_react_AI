from query import * 
import argparse
import requests
from pymongo import MongoClient
import google.generativeai as genai
GEMINI_API_KEY = read_env_key("GEMINI_API_KEY")
genai.configure(api_key=GEMINI_API_KEY)

def build_context(docs):
    context = ""
    for i, (_, doc) in enumerate(docs, 1):
        context += f"[Doc {i}]\nGi·∫£i th√≠ch: {doc.get('explanation')}\nCode: {doc.get('code')}\nLink: {doc.get('link')}\n\n"
    return context

def ask_groq(question, context, chat_history=None, model="llama3-70b-8192"):
    """
    H√†m g·ªçi Groq API v·ªõi chat history ƒë·ªÉ duy tr√¨ cu·ªôc h·ªôi tho·∫°i
    chat_history: list of {"role": "user/assistant", "content": "..."}
    """
    try:
        api_key = read_env_key("GROQ_API_KEY")
        url = read_env_key("GROQ_URL")
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        with open("prompt.txt", "r", encoding="utf-8") as f:
            system_prompt = f.read().strip()
        
        # T·∫°o messages v·ªõi system prompt + chat history + context hi·ªán t·∫°i
        messages = [{"role": "system", "content": system_prompt}]
        
        # Th√™m l·ªãch s·ª≠ chat (n·∫øu c√≥)
        if chat_history:
            messages.extend(chat_history)
        
        # Th√™m c√¢u h·ªèi hi·ªán t·∫°i v·ªõi context
        current_message = f"Context:\n{context}\n\nQuestion: {question}"
        messages.append({"role": "user", "content": current_message})
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": 0.2,
            "max_tokens": 1024
        }
        resp = requests.post(url, headers=headers, json=payload, timeout=60)
        if resp.status_code == 200:
            return resp.json()["choices"][0]["message"]["content"]
        else:
            error_msg = f"Groq API error: {resp.status_code} {resp.text}"
            print(error_msg)
            return f"‚ùå L·ªói API: {error_msg}"
    except Exception as e:
        error_msg = f"Exception in ask_groq: {str(e)}"
        print(error_msg)
        return f"‚ùå L·ªói h·ªá th·ªëng: {error_msg}"

def get_chatbot_response(question, chat_history=None, topk=5, model="llama3-70b-8192"):
    """
    H√†m ch√≠nh ƒë·ªÉ l·∫•y ph·∫£n h·ªìi t·ª´ chatbot v·ªõi chat history
    Returns: (answer, context_info, updated_chat_history)
    """
    try:
        # K·∫øt n·ªëi MongoDB
        MONGODB_URI = read_env_key("MONGODB_URI")
        client = MongoClient(MONGODB_URI)
        db = client.get_default_database()
        collection = db["normalized"]
        
        # T·∫°o embedding v√† t√¨m context
        query_emb = get_embedding(question)
        query_emb = resize_embedding(query_emb, 1024)
        results = find_top_k(query_emb, collection, k=topk)
        context = build_context(results)
        
        # L·∫•y ph·∫£n h·ªìi t·ª´ Groq v·ªõi chat history
        answer = ask_groq(question, context, chat_history, model)
        
        # C·∫≠p nh·∫≠t chat history
        if chat_history is None:
            chat_history = []
        
        new_chat_history = chat_history.copy()
        new_chat_history.append({"role": "user", "content": question})
        new_chat_history.append({"role": "assistant", "content": answer})
        
        # Gi·ªõi h·∫°n chat history (ch·ªâ gi·ªØ 10 tin nh·∫Øn g·∫ßn nh·∫•t)
        if len(new_chat_history) > 20:  # 10 c·∫∑p user-assistant
            new_chat_history = new_chat_history[-20:]
        
        # T·∫°o th√¥ng tin context ƒë·ªÉ hi·ªÉn th·ªã
        context_info = "\n\n".join([
            f"--- Context #{i+1} (similarity={score:.3f}) ---\nExplanation: {doc.get('explanation', 'N/A')}\nCode: {doc.get('code', 'N/A')}\nLink: {doc.get('link', 'N/A')}"
            for i, (score, doc) in enumerate(results)
        ])
        
        return answer, context_info, new_chat_history
        
    except Exception as e:
        error_msg = f"‚ùå L·ªói h·ªá th·ªëng: {str(e)}"
        print(error_msg)
        return error_msg, "Kh√¥ng th·ªÉ l·∫•y context do l·ªói", chat_history or []

def main():
    parser = argparse.ArgumentParser(description="Chatbot embedding + Groq")
    parser.add_argument('--question', type=str, help='C√¢u h·ªèi ƒë·∫ßu v√†o')
    parser.add_argument('--topk', type=int, default=5, help='S·ªë l∆∞·ª£ng context top K')
    parser.add_argument('--model', type=str, default="llama3-70b-8192", help='Model Groq (llama3-70b-8192, mixtral-8x7b-32768,...)')
    args = parser.parse_args()

    chat_history = []
    
    if args.question:
        # Single question mode
        answer, context_info, _ = get_chatbot_response(args.question, chat_history, args.topk, args.model)
        print(f"\n=== C√¢u h·ªèi ===\n{args.question}")
        print(f"\n=== Tr·∫£ l·ªùi t·ª´ Groq ===\n{answer}")
        print(f"\n=== Context ƒë∆∞·ª£c s·ª≠ d·ª•ng ===\n{context_info}")
    else:
        # Interactive chat mode
        print("ü§ñ Ch√†o b·∫°n! T√¥i l√† chatbot ReactJS. G√µ 'quit' ƒë·ªÉ tho√°t.")
        while True:
            question = input("\nüë§ B·∫°n: ").strip()
            if question.lower() in ['quit', 'exit', 'q']:
                print("üëã T·∫°m bi·ªát!")
                break
            if not question:
                continue
                
            print("üîç ƒêang t√¨m ki·∫øm v√† x·ª≠ l√Ω...")
            answer, context_info, chat_history = get_chatbot_response(question, chat_history, args.topk, args.model)
            print(f"\nü§ñ Bot: {answer}")
            
            # Debug info
            print(f"\nüìä Debug - Chat history length: {len(chat_history)} messages")
            print(f"üìã Context info: {len(context_info)} characters")

if __name__ == "__main__":
    main()
